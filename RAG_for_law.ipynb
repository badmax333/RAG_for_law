{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ JSON –Ω–∞ –æ—Å–Ω–≤–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –ü–î–î –≤ –†–§\n",
        "---"
      ],
      "metadata": {
        "id": "bwRnOApP5XA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-docx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivQ3apMadm1p",
        "outputId": "ac89b6e4-f8cb-4d69-c16b-0a556a420e12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "from docx import Document\n",
        "\n",
        "def read_docx_file(file_path):\n",
        "    \"\"\"–ß—Ç–µ–Ω–∏–µ .docx —Ñ–∞–π–ª–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
        "    doc = Document(file_path)\n",
        "    full_text = []\n",
        "\n",
        "    for paragraph in doc.paragraphs:\n",
        "        if paragraph.text.strip():  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏\n",
        "            full_text.append(paragraph.text)\n",
        "\n",
        "    return '\\n'.join(full_text)\n",
        "\n",
        "def parse_pdd_to_json(text):\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    result = []\n",
        "    current_section = None\n",
        "    current_content = []\n",
        "    current_main_point = None\n",
        "    current_sub_points = []\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        section_match = re.match(r'^(\\d+)\\.\\s+(.+)$', line)\n",
        "        if section_match:\n",
        "            if current_section is not None:\n",
        "                save_current_section(current_section, current_content, current_main_point, current_sub_points, result)\n",
        "\n",
        "            current_section = {\n",
        "                'num': section_match.group(1),\n",
        "                'name': section_match.group(2).strip()\n",
        "            }\n",
        "            current_content = []\n",
        "            current_main_point = None\n",
        "            current_sub_points = []\n",
        "            continue\n",
        "\n",
        "        main_p_match = re.match(r'^(\\d+\\.\\d+)\\.\\s+(.+)$', line)\n",
        "        if main_p_match and current_section is not None:\n",
        "            if current_main_point is not None:\n",
        "                save_current_main_point(current_content, current_main_point, current_sub_points)\n",
        "\n",
        "            current_main_point = {\n",
        "                'p_num': main_p_match.group(1),\n",
        "                'full_text': main_p_match.group(2).strip(),\n",
        "                'text_buffer': [main_p_match.group(2).strip()]\n",
        "            }\n",
        "            current_sub_points = []\n",
        "            continue\n",
        "\n",
        "        sub_p_match = re.match(r'^(\\d+\\.\\d+\\.\\d+)\\.\\s+(.+)$', line)\n",
        "        if sub_p_match and current_section is not None and current_main_point is not None:\n",
        "            if not current_sub_points and current_main_point['text_buffer']:\n",
        "                current_main_point['full_text'] = ' '.join(current_main_point['text_buffer']).strip()\n",
        "\n",
        "            sub_point = {\n",
        "                'p_num': sub_p_match.group(1),\n",
        "                'full_text': sub_p_match.group(2).strip(),\n",
        "                'text_buffer': [sub_p_match.group(2).strip()]\n",
        "            }\n",
        "            current_sub_points.append(sub_point)\n",
        "            continue\n",
        "\n",
        "        if current_main_point is not None and line:\n",
        "            if current_sub_points:\n",
        "                current_sub_points[-1]['text_buffer'].append(line)\n",
        "            else:\n",
        "                current_main_point['text_buffer'].append(line)\n",
        "\n",
        "    if current_section is not None:\n",
        "        save_current_section(current_section, current_content, current_main_point, current_sub_points, result)\n",
        "\n",
        "    return result\n",
        "\n",
        "def save_current_main_point(content_list, main_point, sub_points):\n",
        "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø—É–Ω–∫—Ç —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É\"\"\"\n",
        "    if main_point is None:\n",
        "        return\n",
        "\n",
        "    if main_point['text_buffer']:\n",
        "        main_point['full_text'] = ' '.join(main_point['text_buffer']).strip()\n",
        "\n",
        "    point_structure = {\n",
        "        'p_num': main_point['p_num'],\n",
        "        'full_text': main_point['full_text']\n",
        "    }\n",
        "\n",
        "    if sub_points:\n",
        "        for sub_point in sub_points:\n",
        "            if sub_point['text_buffer']:\n",
        "                sub_point['full_text'] = ' '.join(sub_point['text_buffer']).strip()\n",
        "\n",
        "        point_structure['p_sup'] = [\n",
        "            {\n",
        "                'p_num': sub_point['p_num'],\n",
        "                'full_text': sub_point['full_text']\n",
        "            }\n",
        "            for sub_point in sub_points\n",
        "        ]\n",
        "\n",
        "    content_list.append(point_structure)\n",
        "\n",
        "def save_current_section(section, content_list, main_point, sub_points, result_list):\n",
        "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—É—â–∏–π —Ä–∞–∑–¥–µ–ª –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç\"\"\"\n",
        "    if section is None:\n",
        "        return\n",
        "\n",
        "    if main_point is not None:\n",
        "        save_current_main_point(content_list, main_point, sub_points)\n",
        "\n",
        "    if content_list:\n",
        "        section_data = {\n",
        "            'section': {\n",
        "                'sec_num': section['num'],\n",
        "                'name': section['name'],\n",
        "                'content': content_list\n",
        "            }\n",
        "        }\n",
        "        result_list.append(section_data)\n",
        "\n",
        "def process_pdd_file(input_file, output_file):\n",
        "    try:\n",
        "        print(f\"–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: {input_file}\")\n",
        "        content = read_docx_file(input_file)\n",
        "\n",
        "        print(\"–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ...\")\n",
        "        parsed_data = parse_pdd_to_json(content)\n",
        "\n",
        "        print(f\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {output_file}\")\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(parsed_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        return parsed_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}\")\n",
        "        return None\n",
        "\n",
        "def print_statistics(parsed_data):\n",
        "    \"\"\"–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º –¥–∞–Ω–Ω—ã–º\"\"\"\n",
        "    if not parsed_data:\n",
        "        print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏\")\n",
        "        return\n",
        "\n",
        "    print(f\"–ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: {len(parsed_data)}\")\n",
        "\n",
        "    total_main_points = 0\n",
        "    total_sub_points = 0\n",
        "    sections_with_subpoints = 0\n",
        "\n",
        "    for section_data in parsed_data:\n",
        "        section = section_data['section']\n",
        "        main_points_count = len(section['content'])\n",
        "        total_main_points += main_points_count\n",
        "\n",
        "        sub_points_in_section = 0\n",
        "        for point in section['content']:\n",
        "            if 'p_sup' in point:\n",
        "                sub_points_count = len(point['p_sup'])\n",
        "                total_sub_points += sub_points_count\n",
        "                sub_points_in_section += sub_points_count\n",
        "\n",
        "        if sub_points_in_section > 0:\n",
        "            sections_with_subpoints += 1\n",
        "\n",
        "        print(f\"–†–∞–∑–¥–µ–ª {section['sec_num']}. {section['name']}:\")\n",
        "        print(f\"  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: {main_points_count}\")\n",
        "        print(f\"  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: {sub_points_in_section}\")\n",
        "\n",
        "    print(f\"\\n–ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\")\n",
        "    print(f\"–í—Å–µ–≥–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: {total_main_points}\")\n",
        "    print(f\"–í—Å–µ–≥–æ –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤: {total_sub_points}\")\n",
        "    print(f\"–†–∞–∑–¥–µ–ª–æ–≤ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏: {sections_with_subpoints}\")\n",
        "\n",
        "def print_example_structure(parsed_data, section_index=0, point_index=0):\n",
        "    \"\"\"–í—ã–≤–æ–¥–∏—Ç –ø—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏\"\"\"\n",
        "    if not parsed_data or section_index >= len(parsed_data):\n",
        "        print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞\")\n",
        "        return\n",
        "\n",
        "    section = parsed_data[section_index]['section']\n",
        "    print(f\"\\n–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–∞–∑–¥–µ–ª–∞ {section['sec_num']}. {section['name']}:\")\n",
        "\n",
        "    if section['content'] and point_index < len(section['content']):\n",
        "        point = section['content'][point_index]\n",
        "        print(f\"–û—Å–Ω–æ–≤–Ω–æ–π –ø—É–Ω–∫—Ç: {point['p_num']}\")\n",
        "        print(f\"–¢–µ–∫—Å—Ç: {point['full_text'][:100]}...\")\n",
        "\n",
        "        if 'p_sup' in point:\n",
        "            print(f\"–ü–æ–¥–ø—É–Ω–∫—Ç—ã ({len(point['p_sup'])}):\")\n",
        "            for sub_point in point['p_sup'][:2]:\n",
        "                print(f\"  - {sub_point['p_num']}: {sub_point['full_text'][:80]}...\")\n",
        "        else:\n",
        "            print(\"–ü–æ–¥–ø—É–Ω–∫—Ç—ã: –Ω–µ—Ç\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_filename = \"/content/–ø–¥–¥.docx\"\n",
        "    output_filename = \"pdd_structured.json\"\n",
        "\n",
        "    result = process_pdd_file(input_filename, output_filename)\n",
        "\n",
        "    if result:\n",
        "        print(f\"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {output_filename}\")\n",
        "        print_statistics(result)\n",
        "        print_example_structure(result)\n",
        "        simplified_output = \"pdd_simplified_example.json\"\n",
        "        with open(simplified_output, 'w', encoding='utf-8') as f:\n",
        "            simplified_data = result[:2] if len(result) >= 2 else result\n",
        "            json.dump(simplified_data, f, ensure_ascii=False, indent=2)\n",
        "        print(f\"\\n–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {simplified_output}\")\n",
        "\n",
        "    else:\n",
        "        print(\"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rFqKUT3dDPH",
        "outputId": "dafb478c-0386-4bfa-884e-4a4f6a1dd052"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞: /content/–ø–¥–¥.docx\n",
            "–ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ...\n",
            "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: pdd_structured.json\n",
            "–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ pdd_structured.json\n",
            "–ù–∞–π–¥–µ–Ω–æ —Ä–∞–∑–¥–µ–ª–æ–≤: 30\n",
            "–†–∞–∑–¥–µ–ª 2. –û–±—â–∏–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≤–æ–¥–∏—Ç–µ–ª–µ–π:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 7\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 6\n",
            "–†–∞–∑–¥–µ–ª 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 6\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 4. –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–µ—à–µ—Ö–æ–¥–æ–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 8\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 5. –û–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 2\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 6. –°–∏–≥–Ω–∞–ª—ã —Å–≤–µ—Ç–æ—Ñ–æ—Ä–∞ –∏ —Ä–µ–≥—É–ª–∏—Ä–æ–≤—â–∏–∫–∞:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 16\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 7. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∞–≤–∞—Ä–∏–π–Ω–æ–π —Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –∑–Ω–∞–∫–∞ –∞–≤–∞—Ä–∏–π–Ω–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 3\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 8. –ù–∞—á–∞–ª–æ –¥–≤–∏–∂–µ–Ω–∏—è, –º–∞–Ω–µ–≤—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 12\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 9. –†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ –Ω–∞ –ø—Ä–æ–µ–∑–∂–µ–π —á–∞—Å—Ç–∏:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 12\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 10. –°–∫–æ—Ä–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 11. –û–±–≥–æ–Ω, –æ–ø–µ—Ä–µ–∂–µ–Ω–∏–µ, –≤—Å—Ç—Ä–µ—á–Ω—ã–π —Ä–∞–∑—ä–µ–∑–¥:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 7\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 12. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ —Å—Ç–æ—è–Ω–∫–∞:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 8\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 13. –ü—Ä–æ–µ–∑–¥ –ø–µ—Ä–µ–∫—Ä–µ—Å—Ç–∫–æ–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 20\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 15. –î–≤–∏–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∂–µ–ª–µ–∑–Ω–æ–¥–æ—Ä–æ–∂–Ω—ã–µ –ø—É—Ç–∏:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 16. –î–≤–∏–∂–µ–Ω–∏–µ –ø–æ –∞–≤—Ç–æ–º–∞–≥–∏—Å—Ç—Ä–∞–ª—è–º:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 3\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 17. –î–≤–∏–∂–µ–Ω–∏–µ –≤ –∂–∏–ª—ã—Ö –∑–æ–Ω–∞—Ö:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 4\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 18. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –º–∞—Ä—à—Ä—É—Ç–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 3\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 19. –ü–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–Ω–µ—à–Ω–∏–º–∏ —Å–≤–µ—Ç–æ–≤—ã–º–∏ –ø—Ä–∏–±–æ—Ä–∞–º–∏ –∏ –∑–≤—É–∫–æ–≤—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 11\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 20. –ë—É–∫—Å–∏—Ä–æ–≤–∫–∞ –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 4\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 21. –£—á–µ–±–Ω–∞—è –µ–∑–¥–∞:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 6\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 22. –ü–µ—Ä–µ–≤–æ–∑–∫–∞ –ª—é–¥–µ–π:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 9\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 23. –ü–µ—Ä–µ–≤–æ–∑–∫–∞ –≥—Ä—É–∑–æ–≤:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 24. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –¥–≤–∏–∂–µ–Ω–∏—é –≤–µ–ª–æ—Å–∏–ø–µ–¥–æ–≤, –º–æ–ø–µ–¥–æ–≤, –≥—É–∂–µ–≤—ã—Ö –ø–æ–≤–æ–∑–æ–∫, –∞ —Ç–∞–∫–∂–µ –ø—Ä–æ–≥–æ–Ω—É –∂–∏–≤–æ—Ç–Ω—ã—Ö:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 7\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 4. –ì—Ä—É–∑–æ–≤–æ–π –∞–≤—Ç–æ–º–æ–±–∏–ª—å —Å –±–æ—Ä—Ç–æ–≤–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –¥–ª—è –ø–µ—Ä–µ–≤–æ–∑–∫–∏ –ª—é–¥–µ–π, –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω —Å–∏–¥–µ–Ω—å—è–º–∏, –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–º–∏ –Ω–∞ –≤—ã—Å–æ—Ç–µ 0,3 - 0,5 –º –æ—Ç –ø–æ–ª–∞ –∏ –Ω–µ –º–µ–Ω–µ–µ 0,3 –º –æ—Ç –≤–µ—Ä—Ö–Ω–µ–≥–æ –∫—Ä–∞—è –±–æ—Ä—Ç–∞. –°–∏–¥–µ–Ω—å—è, —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–µ –≤–¥–æ–ª—å –∑–∞–¥–Ω–µ–≥–æ –∏–ª–∏ –±–æ–∫–æ–≤–æ–≥–æ –±–æ—Ä—Ç–∞, –¥–æ–ª–∂–Ω—ã –∏–º–µ—Ç—å –ø—Ä–æ—á–Ω—ã–µ —Å–ø–∏–Ω–∫–∏.:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 1\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 1. –¢–æ—Ä–º–æ–∑–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 2. –†—É–ª–µ–≤–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 3\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 3. –í–Ω–µ—à–Ω–∏–µ —Å–≤–µ—Ç–æ–≤—ã–µ –ø—Ä–∏–±–æ—Ä—ã:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 6\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 4. –°—Ç–µ–∫–ª–æ–æ—á–∏—Å—Ç–∏—Ç–µ–ª–∏ –∏ —Å—Ç–µ–∫–ª–æ–æ–º—ã–≤–∞—Ç–µ–ª–∏ –≤–µ—Ç—Ä–æ–≤–æ–≥–æ —Å—Ç–µ–∫–ª–∞:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 2\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 5. –ö–æ–ª–µ—Å–∞ –∏ —à–∏–Ω—ã:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 6. –î–≤–∏–≥–∞—Ç–µ–ª—å:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 5\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "–†–∞–∑–¥–µ–ª 7. –ü—Ä–æ—á–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏:\n",
            "  - –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 18\n",
            "  - –ü–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 0\n",
            "\n",
            "–ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:\n",
            "–í—Å–µ–≥–æ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤: 208\n",
            "–í—Å–µ–≥–æ –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤: 6\n",
            "–†–∞–∑–¥–µ–ª–æ–≤ —Å –ø–æ–¥–ø—É–Ω–∫—Ç–∞–º–∏: 1\n",
            "\n",
            "–ü—Ä–∏–º–µ—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–∞–∑–¥–µ–ª–∞ 2. –û–±—â–∏–µ –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≤–æ–¥–∏—Ç–µ–ª–µ–π:\n",
            "–û—Å–Ω–æ–≤–Ω–æ–π –ø—É–Ω–∫—Ç: 2.1\n",
            "–¢–µ–∫—Å—Ç: –í–æ–¥–∏—Ç–µ–ª—å –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞ –æ–±—è–∑–∞–Ω:...\n",
            "–ü–æ–¥–ø—É–Ω–∫—Ç—ã (2):\n",
            "  - 2.1.1: –ò–º–µ—Ç—å –ø—Ä–∏ —Å–µ–±–µ –∏ –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –º–∏–ª–∏—Ü–∏–∏ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –∏–º, –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: ...\n",
            "  - 2.1.2: –ü—Ä–∏ –¥–≤–∏–∂–µ–Ω–∏–∏ –Ω–∞ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–º —Å—Ä–µ–¥—Å—Ç–≤–µ, –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–Ω–æ–º —Ä–µ–º–Ω—è–º–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –±—ã—Ç—å ...\n",
            "\n",
            "–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: pdd_simplified_example.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ—Å–ª–µ —Å–æ–±—Ä–∞–Ω–Ω—ã–π JSON –±—ã–ª –ø—Ä–æ–≥–Ω–∞–Ω —á–µ—Ä–µ–∑ LLM c —Ü–µ–ª—å—é —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–≤—Ö –ø–æ–ª–µ–π —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–∞–∂–¥–æ–π —Å–µ–∫—Ü–∏–∏ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Å–µ–∫—Ü–∏–π –ü–î–î"
      ],
      "metadata": {
        "id": "xtfo4kIo5vP0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í–∞—Ä–∏–∞–Ω—Ç faiss –ø–æ –∏—Ç–æ–≥–æ–≤–æ–º—É —Ç–µ–∫—Å—Ç—É —Å —Ç—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–º –ø–æ–∏—Å–∫–æ–º:\n",
        "---\n",
        "- —Å–µ–∫—Ü–∏—è\n",
        "- –ø—É–Ω–∫—Ç\n",
        "- –ø–æ–¥–ø—É–Ω–∫—Ç\n",
        "\n",
        "–ø–ª—é—Å —Å–æ–∑–¥–∞–Ω –∏–≥—Ä—É—à–µ—á–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤–∏–∫, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –æ—Ü–µ–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –≤—ã–ø–æ–ª–Ω—è–µ–º–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–π –≤—ã–¥–∞—á–∏\n",
        "\n"
      ],
      "metadata": {
        "id": "b2XzRGqb3lxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu sentence-transformers numpy scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4T9EFpAuOlN",
        "outputId": "07a6799a-1f2f-4330-b651-c263a5af0a8c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community faiss-cpu sentence-transformers langchain-huggingface"
      ],
      "metadata": {
        "id": "Wh8UufJQkAGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from typing import List, Dict, Tuple, Any\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "class InteractiveThreeLevelSearch:\n",
        "    def __init__(self, json_file_path, model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'):\n",
        "        self.json_file_path = json_file_path\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.sections = []\n",
        "        self.section_texts = []  # –û–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ name + description\n",
        "        self.section_embeddings = None\n",
        "        self.section_index = None\n",
        "        self.content_data = []\n",
        "        self.content_embeddings = None\n",
        "        self.content_index = None\n",
        "        self.qa_history = []\n",
        "        self.section_structure_cache = {}\n",
        "\n",
        "    def load_data(self):\n",
        "        \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞\"\"\"\n",
        "        print(\"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ü–î–î...\")\n",
        "        with open(self.json_file_path, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        self.sections = []\n",
        "        self.section_texts = []  # name + description\n",
        "        self.content_data = []\n",
        "\n",
        "        for section_item in data:\n",
        "            section = section_item['section']\n",
        "            sec_num = section['sec_num']\n",
        "            name = section['name']\n",
        "            description = section['description']\n",
        "\n",
        "\n",
        "            section_text = f\"{name}. {description}\"\n",
        "\n",
        "            self.sections.append({\n",
        "                'sec_num': sec_num,\n",
        "                'name': name,\n",
        "                'description': description,\n",
        "                'section_text': section_text,\n",
        "                'original_data': section\n",
        "            })\n",
        "            self.section_texts.append(section_text)\n",
        "\n",
        "            section_idx = len(self.sections) - 1\n",
        "            if 'content' in section:\n",
        "                for content_item in section['content']:\n",
        "                    p_num = content_item['p_num']\n",
        "                    full_text = content_item['full_text']\n",
        "\n",
        "                    self.content_data.append({\n",
        "                        'section_idx': section_idx,\n",
        "                        'p_num': p_num,\n",
        "                        'full_text': full_text,\n",
        "                        'is_subpoint': False,\n",
        "                        'parent_p_num': None,\n",
        "                        'original_data': content_item\n",
        "                    })\n",
        "\n",
        "                    if 'p_sup' in content_item:\n",
        "                        for subpoint in content_item['p_sup']:\n",
        "                            sub_p_num = subpoint['p_num']\n",
        "                            sub_full_text = subpoint['full_text']\n",
        "\n",
        "                            self.content_data.append({\n",
        "                                'section_idx': section_idx,\n",
        "                                'p_num': sub_p_num,\n",
        "                                'full_text': sub_full_text,\n",
        "                                'is_subpoint': True,\n",
        "                                'parent_p_num': p_num,\n",
        "                                'original_data': subpoint\n",
        "                            })\n",
        "\n",
        "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.sections)} —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ {len(self.content_data)} –ø—É–Ω–∫—Ç–æ–≤/–ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤\")\n",
        "\n",
        "    def build_indexes(self):\n",
        "        \"\"\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–æ–≤ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –í–°–ï–• –≤–µ–∫—Ç–æ—Ä–æ–≤\"\"\"\n",
        "        print(\"üî® –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...\")\n",
        "\n",
        "\n",
        "        if self.section_texts:\n",
        "            section_embeddings = self.model.encode(self.section_texts)\n",
        "            faiss.normalize_L2(section_embeddings)\n",
        "            self.section_embeddings = section_embeddings.astype('float32')\n",
        "            self.section_index = faiss.IndexFlatIP(self.section_embeddings.shape[1])\n",
        "            self.section_index.add(self.section_embeddings)\n",
        "            print(f\"‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –∏–Ω–¥–µ–∫—Å —Ä–∞–∑–¥–µ–ª–æ–≤: {len(self.section_texts)} –≤–µ–∫—Ç–æ—Ä–æ–≤ (name + description)\")\n",
        "\n",
        "\n",
        "        content_texts = [item['full_text'] for item in self.content_data]\n",
        "        if content_texts:\n",
        "            content_embeddings = self.model.encode(content_texts)\n",
        "            faiss.normalize_L2(content_embeddings)\n",
        "            self.content_embeddings = content_embeddings.astype('float32')\n",
        "            self.content_index = faiss.IndexFlatIP(self.content_embeddings.shape[1])\n",
        "            self.content_index.add(self.content_embeddings)\n",
        "            print(f\"‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –∏–Ω–¥–µ–∫—Å –ø—É–Ω–∫—Ç–æ–≤: {len(content_texts)} –≤–µ–∫—Ç–æ—Ä–æ–≤\")\n",
        "\n",
        "        print(\"üéØ –í—Å–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\")\n",
        "\n",
        "    def save_indexes(self, cache_dir):\n",
        "        \"\"\"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ –≤ –∫—ç—à\"\"\"\n",
        "        try:\n",
        "            if not os.path.exists(cache_dir):\n",
        "                os.makedirs(cache_dir)\n",
        "\n",
        "            faiss.write_index(self.sections_index, os.path.join(cache_dir, 'sections_index.faiss'))\n",
        "            faiss.write_index(self.content_index, os.path.join(cache_dir, 'content_index.faiss'))\n",
        "\n",
        "            metadata = {\n",
        "                'sections': self.sections,\n",
        "                'section_texts': self.section_texts,\n",
        "                'section_embeddings': self.section_embeddings,\n",
        "                'content_data': self.content_data,\n",
        "                'content_embeddings': self.content_embeddings\n",
        "            }\n",
        "\n",
        "            with open(os.path.join(cache_dir, 'metadata.pkl'), 'wb') as f:\n",
        "                pickle.dump(metadata, f)\n",
        "\n",
        "            print(\"‚úÖ –ò–Ω–¥–µ–∫—Å—ã —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: {e}\")\n",
        "\n",
        "    def load_indexes(self, cache_dir):\n",
        "      \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω–¥–µ–∫—Å–æ–≤ –∏–∑ –∫—ç—à–∞\"\"\"\n",
        "      try:\n",
        "          if not os.path.exists(cache_dir):\n",
        "              return False\n",
        "\n",
        "          index_files = [\n",
        "              os.path.join(cache_dir, 'sections_index.faiss'),\n",
        "              os.path.join(cache_dir, 'content_index.faiss')\n",
        "          ]\n",
        "\n",
        "          if not all(os.path.exists(f) for f in index_files):\n",
        "              return False\n",
        "\n",
        "          self.sections_index = faiss.read_index(index_files[0])\n",
        "          self.content_index = faiss.read_index(index_files[1])\n",
        "\n",
        "          with open(os.path.join(cache_dir, 'metadata.pkl'), 'rb') as f:\n",
        "              data = pickle.load(f)\n",
        "\n",
        "          self.sections = data.get('sections', [])\n",
        "          self.section_texts = data.get('section_texts', [])\n",
        "          self.section_embeddings = data.get('section_embeddings', [])\n",
        "          self.content_data = data.get('content_data', [])\n",
        "          self.content_embeddings = data.get('content_embeddings', [])\n",
        "\n",
        "          print(\"‚úÖ –ò–Ω–¥–µ–∫—Å—ã —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ –∫—ç—à–∞\")\n",
        "          return True\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–Ω–¥–µ–∫—Å–æ–≤: {e}\")\n",
        "          return False\n",
        "\n",
        "    def initialize(self, force_rebuild=False):\n",
        "        \"\"\"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞\"\"\"\n",
        "        cache_dir = \"faiss_cache\"\n",
        "\n",
        "        if not force_rebuild and self.load_indexes(cache_dir):\n",
        "            return True\n",
        "\n",
        "        print(\"üî® –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ —Å –Ω—É–ª—è...\")\n",
        "        self.load_data()\n",
        "        self.build_indexes()\n",
        "        self.save_indexes(cache_dir)\n",
        "        return True\n",
        "\n",
        "    def search(self, query: str, top_k_sections: int = 3, top_k_content: int = 10, threshold: float = 0.3) -> List[Dict]:\n",
        "        \"\"\"–¢—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º name –∏ description —Ä–∞–∑–¥–µ–ª–æ–≤\"\"\"\n",
        "\n",
        "        # –£—Ä–æ–≤–µ–Ω—å 1: –ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º (name + description)\n",
        "        query_embedding = self.model.encode([query]).astype('float32')\n",
        "        faiss.normalize_L2(query_embedding)\n",
        "\n",
        "        section_scores, section_indices = self.section_index.search(query_embedding, top_k_sections)\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # –£—Ä–æ–≤–µ–Ω—å 2 –∏ 3: –ü–æ–∏—Å–∫ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∞—Ö\n",
        "        for section_score, section_idx in zip(section_scores[0], section_indices[0]):\n",
        "            if section_score < threshold:\n",
        "                continue\n",
        "\n",
        "            section_info = self.sections[section_idx]\n",
        "\n",
        "            section_content_indices = [\n",
        "                i for i, item in enumerate(self.content_data)\n",
        "                if item['section_idx'] == section_idx\n",
        "            ]\n",
        "\n",
        "            if not section_content_indices:\n",
        "                continue\n",
        "\n",
        "            section_content_embeddings = self.content_embeddings[section_content_indices]\n",
        "\n",
        "            temp_index = faiss.IndexFlatIP(section_content_embeddings.shape[1])\n",
        "            temp_index.add(section_content_embeddings)\n",
        "\n",
        "            content_scores, content_local_indices = temp_index.search(\n",
        "                query_embedding,\n",
        "                min(top_k_content, len(section_content_indices))\n",
        "            )\n",
        "\n",
        "            section_results = []\n",
        "            for content_score, local_idx in zip(content_scores[0], content_local_indices[0]):\n",
        "                if content_score < threshold:\n",
        "                    continue\n",
        "\n",
        "                global_idx = section_content_indices[local_idx]\n",
        "                content_item = self.content_data[global_idx]\n",
        "\n",
        "\n",
        "                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ [0, 1] –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "                section_score_norm = (section_score + 1) / 2\n",
        "                content_score_norm = (content_score + 1) / 2\n",
        "                combined_score = section_score_norm * content_score_norm\n",
        "\n",
        "                section_results.append({\n",
        "                    'p_num': content_item['p_num'],\n",
        "                    'full_text': content_item['full_text'],\n",
        "                    'is_subpoint': content_item['is_subpoint'],\n",
        "                    'parent_p_num': content_item['parent_p_num'],\n",
        "                    'section_score': float(section_score),\n",
        "                    'content_score': float(content_score),\n",
        "                    'combined_score': combined_score,\n",
        "                    'section_score_norm': section_score_norm,\n",
        "                    'content_score_norm': content_score_norm\n",
        "                })\n",
        "\n",
        "            section_results.sort(key=lambda x: (x['section_score_norm'], x['content_score_norm'], x['combined_score']), reverse=True)\n",
        "\n",
        "            if section_results:\n",
        "                results.append({\n",
        "                    'section': {\n",
        "                        'sec_num': section_info['sec_num'],\n",
        "                        'name': section_info['name'],\n",
        "                        'description': section_info['description'],\n",
        "                        'section_text': section_info['section_text'],\n",
        "                        'score': float(section_score),\n",
        "                        'score_norm': section_score_norm\n",
        "                    },\n",
        "                    'content': section_results\n",
        "                })\n",
        "\n",
        "        results.sort(key=lambda x: max([item['section_score_norm'] for item in x['content']]), reverse=True)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _parse_p_num(self, p_num: str) -> Tuple[int, ...]:\n",
        "        \"\"\"–ü–∞—Ä—Å–∏–Ω–≥ –Ω–æ–º–µ—Ä–æ–≤ –ø—É–Ω–∫—Ç–æ–≤ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏\"\"\"\n",
        "        parts = re.findall(r'\\d+', p_num)\n",
        "        return tuple(int(part) for part in parts)\n",
        "\n",
        "    def search_and_display(self, query: str):\n",
        "        \"\"\"–ü–æ–∏—Å–∫ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\"\"\"\n",
        "        print(f\"\\nüîç –ü–æ–∏—Å–∫: '{query}'\")\n",
        "        print(\"=\" * 80)\n",
        "\n",
        "        start_time = datetime.now()\n",
        "        results = self.search(query, top_k_sections=3, top_k_content=5, threshold=0.2)\n",
        "        search_time = (datetime.now() - start_time).total_seconds()\n",
        "\n",
        "        total_results = sum(len(result['content']) for result in results)\n",
        "\n",
        "        self.qa_history.append({\n",
        "            'query': query,\n",
        "            'timestamp': datetime.now(),\n",
        "            'results_count': total_results,\n",
        "            'search_time': search_time\n",
        "        })\n",
        "\n",
        "        if not results:\n",
        "            print(\"‚ùå –ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\")\n",
        "            print(\"üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞\")\n",
        "            return\n",
        "\n",
        "        print(f\"‚úÖ –ù–∞–π–¥–µ–Ω–æ {total_results} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ {search_time:.2f} —Å–µ–∫\")\n",
        "        print(\"üìä –ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º —É—á–∏—Ç—ã–≤–∞–µ—Ç: –ù–∞–∑–≤–∞–Ω–∏–µ + –û–ø–∏—Å–∞–Ω–∏–µ\")\n",
        "        print()\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            section = result['section']\n",
        "            print(f\"üìÅ –†–ê–ó–î–ï–õ {i}: {section['sec_num']}. {section['name']}\")\n",
        "            print(f\"   üìù –û–ø–∏—Å–∞–Ω–∏–µ: {section['description']}\")\n",
        "            print(f\"   üéØ –°—Ö–æ–¥—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–∞: {section['score']:.3f}\")\n",
        "            print()\n",
        "\n",
        "            for j, content in enumerate(result['content'], 1):\n",
        "                indent = \"    \"\n",
        "                prefix = f\"{content['p_num']}\"\n",
        "                if content['is_subpoint']:\n",
        "                    prefix = f\"  ‚Ü≥ {content['p_num']}\"\n",
        "\n",
        "                print(f\"{indent}{prefix}\")\n",
        "                text_preview = content['full_text'][:150] + \"...\" if len(content['full_text']) > 150 else content['full_text']\n",
        "                print(f\"{indent}   {text_preview}\")\n",
        "                print(f\"{indent}   üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª={content['section_score']:.3f}, –ø—É–Ω–∫—Ç={content['content_score']:.3f}\")\n",
        "                print(f\"{indent}   üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: {content['combined_score']:.3f}\")\n",
        "                print()\n",
        "\n",
        "            print(\"-\" * 80)\n",
        "\n",
        "    def explore_section(self, section_num: str):\n",
        "        \"\"\"–ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ä–∞–∑–¥–µ–ª–∞\"\"\"\n",
        "        print(f\"\\nüîç –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ {section_num}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        section_found = None\n",
        "        for section in self.sections:\n",
        "            if section['sec_num'] == section_num:\n",
        "                section_found = section\n",
        "                break\n",
        "\n",
        "        if not section_found:\n",
        "            print(f\"‚ùå –†–∞–∑–¥–µ–ª {section_num} –Ω–µ –Ω–∞–π–¥–µ–Ω\")\n",
        "            return\n",
        "\n",
        "        print(f\"üìÅ –†–ê–ó–î–ï–õ {section_found['sec_num']}: {section_found['name']}\")\n",
        "        print(f\"üìù {section_found['description']}\")\n",
        "        print(f\"üîç –¢–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞: {section_found['section_text']}\")\n",
        "        print()\n",
        "\n",
        "        section_content = [\n",
        "            item for item in self.content_data\n",
        "            if item['section_idx'] == self.sections.index(section_found)\n",
        "        ]\n",
        "\n",
        "        main_points = {}\n",
        "        for item in section_content:\n",
        "            if not item['is_subpoint']:\n",
        "                main_points[item['p_num']] = {\n",
        "                    'item': item,\n",
        "                    'subpoints': []\n",
        "                }\n",
        "\n",
        "        for item in section_content:\n",
        "            if item['is_subpoint'] and item['parent_p_num'] in main_points:\n",
        "                main_points[item['parent_p_num']]['subpoints'].append(item)\n",
        "\n",
        "\n",
        "        for p_num in sorted(main_points.keys(), key=self._parse_p_num):\n",
        "            main_point = main_points[p_num]\n",
        "            print(f\"üìÑ {p_num}: {main_point['item']['full_text']}\")\n",
        "\n",
        "            for subpoint in sorted(main_point['subpoints'], key=lambda x: self._parse_p_num(x['p_num'])):\n",
        "                print(f\"   ‚Ü≥ {subpoint['p_num']}: {subpoint['full_text']}\")\n",
        "\n",
        "            print()\n",
        "\n",
        "    def show_search_stats(self):\n",
        "        \"\"\"–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–∏—Å–∫–∞\"\"\"\n",
        "        if not self.qa_history:\n",
        "            print(\"üìä –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞ –ø—É—Å—Ç–∞\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û–ò–°–ö–ê\")\n",
        "        print(\"=\" * 40)\n",
        "        print(f\"–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {len(self.qa_history)}\")\n",
        "\n",
        "        recent_queries = self.qa_history[-10:] if len(self.qa_history) > 10 else self.qa_history\n",
        "        avg_results = sum(item['results_count'] for item in recent_queries) / len(recent_queries)\n",
        "        avg_time = sum(item['search_time'] for item in recent_queries) / len(recent_queries)\n",
        "\n",
        "        print(f\"–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {avg_results:.1f}\")\n",
        "        print(f\"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞: {avg_time:.2f} —Å–µ–∫\")\n",
        "        print(f\"–†–∞–∑–º–µ—Ä –±–∞–∑—ã: {len(self.sections)} —Ä–∞–∑–¥–µ–ª–æ–≤, {len(self.content_data)} –ø—É–Ω–∫—Ç–æ–≤\")\n",
        "        print(f\"–ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º: –ù–∞–∑–≤–∞–Ω–∏–µ + –û–ø–∏—Å–∞–Ω–∏–µ\")\n",
        "\n",
        "        print(f\"\\nüéØ –ü–æ—Å–ª–µ–¥–Ω–∏–µ –∑–∞–ø—Ä–æ—Å—ã:\")\n",
        "        for i, item in enumerate(self.qa_history[-5:], 1):\n",
        "            print(f\"  {i}. '{item['query']}' - {item['results_count']} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
        "\n",
        "def interactive_three_level_search():\n",
        "    \"\"\"–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º —Å —Ç—Ä–µ—Ö—É—Ä–æ–≤–Ω–µ–≤—ã–º –ø–æ–∏—Å–∫–æ–º\"\"\"\n",
        "    search_system = InteractiveThreeLevelSearch('pdd.json')\n",
        "    search_system.initialize(force_rebuild=False)\n",
        "\n",
        "    print(\"üéØ –¢–†–ï–•–£–†–û–í–ù–ï–í–´–ô –ü–û–ò–°–ö –ü–û –ü–î–î\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"–£—Ä–æ–≤–Ω–∏ –ø–æ–∏—Å–∫–∞: –†–∞–∑–¥–µ–ª—ã ‚Üí –ü—É–Ω–∫—Ç—ã ‚Üí –ü–æ–¥–ø—É–Ω–∫—Ç—ã\")\n",
        "    print(\"–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ: –†–∞–∑–¥–µ–ª √ó –ü—É–Ω–∫—Ç √ó –ü–æ–¥–ø—É–Ω–∫—Ç\")\n",
        "    print(\"–ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º: –ù–∞–∑–≤–∞–Ω–∏–µ + –û–ø–∏—Å–∞–Ω–∏–µ\")\n",
        "    print(\"\\n–ö–æ–º–∞–Ω–¥—ã:\")\n",
        "    print(\"  '—Ä–∞–∑–¥–µ–ª X' - –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–∞ X\")\n",
        "    print(\"  '–∏—Å—Ç–æ—Ä–∏—è' - –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∏—Å–∫–∞\")\n",
        "    print(\"  '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞' - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\")\n",
        "    print(\"  '–≤—ã—Ö–æ–¥' - –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É\")\n",
        "    print()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nüîç –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –ü–î–î: \").strip()\n",
        "\n",
        "            if query.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:\n",
        "                print(\"\\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
        "                break\n",
        "\n",
        "            if query.lower().startswith('—Ä–∞–∑–¥–µ–ª '):\n",
        "                section_num = query[7:].strip()\n",
        "                search_system.explore_section(section_num)\n",
        "                continue\n",
        "\n",
        "            if query.lower() == '–∏—Å—Ç–æ—Ä–∏—è':\n",
        "                print(f\"\\nüìä –ò—Å—Ç–æ—Ä–∏—è –ø–æ–∏—Å–∫–∞: {len(search_system.qa_history)} –∑–∞–ø—Ä–æ—Å–æ–≤\")\n",
        "                for i, item in enumerate(search_system.qa_history[-5:], 1):\n",
        "                    print(f\"  {i}. '{item['query']}' - {item['results_count']} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\")\n",
        "                continue\n",
        "\n",
        "            if query.lower() == '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞':\n",
        "                search_system.show_search_stats()\n",
        "                continue\n",
        "\n",
        "            if len(query) < 2:\n",
        "                print(\"‚ùå –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∑–∞–ø—Ä–æ—Å\")\n",
        "                continue\n",
        "\n",
        "            search_system.search_and_display(query)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
        "\n",
        "\n",
        "def install_dependencies():\n",
        "    \"\"\"–§—É–Ω–∫—Ü–∏—è –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\"\"\"\n",
        "    try:\n",
        "        import faiss\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        print(\"‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(\"‚ùå –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:\")\n",
        "        print(\"pip install faiss-cpu sentence-transformers\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –ø–æ –ü–î–î...\")\n",
        "    if install_dependencies():\n",
        "        interactive_three_level_search()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nc0hS03uEbE",
        "outputId": "4ab3e67a-d822-4524-8ecb-72ae6d7cd5fc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ –ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞ –ø–æ –ü–î–î...\n",
            "‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã\n",
            "üî® –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤ —Å –Ω—É–ª—è...\n",
            "üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ü–î–î...\n",
            "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 24 —Ä–∞–∑–¥–µ–ª–æ–≤ –∏ 222 –ø—É–Ω–∫—Ç–æ–≤/–ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤\n",
            "üî® –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –∏–Ω–¥–µ–∫—Å–æ–≤...\n",
            "‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –∏–Ω–¥–µ–∫—Å —Ä–∞–∑–¥–µ–ª–æ–≤: 24 –≤–µ–∫—Ç–æ—Ä–æ–≤ (name + description)\n",
            "‚úÖ –ü–æ—Å—Ç—Ä–æ–µ–Ω –∏–Ω–¥–µ–∫—Å –ø—É–Ω–∫—Ç–æ–≤: 222 –≤–µ–∫—Ç–æ—Ä–æ–≤\n",
            "üéØ –í—Å–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞\n",
            "‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤: 'InteractiveThreeLevelSearch' object has no attribute 'sections_index'\n",
            "üéØ –¢–†–ï–•–£–†–û–í–ù–ï–í–´–ô –ü–û–ò–°–ö –ü–û –ü–î–î\n",
            "==================================================\n",
            "–£—Ä–æ–≤–Ω–∏ –ø–æ–∏—Å–∫–∞: –†–∞–∑–¥–µ–ª—ã ‚Üí –ü—É–Ω–∫—Ç—ã ‚Üí –ü–æ–¥–ø—É–Ω–∫—Ç—ã\n",
            "–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ: –†–∞–∑–¥–µ–ª √ó –ü—É–Ω–∫—Ç √ó –ü–æ–¥–ø—É–Ω–∫—Ç\n",
            "–ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º: –ù–∞–∑–≤–∞–Ω–∏–µ + –û–ø–∏—Å–∞–Ω–∏–µ\n",
            "\n",
            "–ö–æ–º–∞–Ω–¥—ã:\n",
            "  '—Ä–∞–∑–¥–µ–ª X' - –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–∞–∑–¥–µ–ª–∞ X\n",
            "  '–∏—Å—Ç–æ—Ä–∏—è' - –ø–æ–∫–∞–∑–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø–æ–∏—Å–∫–∞\n",
            "  '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞' - –ø–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É\n",
            "  '–≤—ã—Ö–æ–¥' - –∑–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–±–æ—Ç—É\n",
            "\n",
            "\n",
            "üîç –í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –ü–î–î: —Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–∞—è –¥–ª—è –¥–≤–∏–∂–µ–Ω–∏—è\n",
            "\n",
            "üîç –ü–æ–∏—Å–∫: '—Å–∫–æ—Ä–æ—Å—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–∞—è –¥–ª—è –¥–≤–∏–∂–µ–Ω–∏—è'\n",
            "================================================================================\n",
            "‚úÖ –ù–∞–π–¥–µ–Ω–æ 15 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∑–∞ 0.03 —Å–µ–∫\n",
            "üìä –ü–æ–∏—Å–∫ –ø–æ —Ä–∞–∑–¥–µ–ª–∞–º —É—á–∏—Ç—ã–≤–∞–µ—Ç: –ù–∞–∑–≤–∞–Ω–∏–µ + –û–ø–∏—Å–∞–Ω–∏–µ\n",
            "\n",
            "üìÅ –†–ê–ó–î–ï–õ 1: 9. –°–∫–æ—Ä–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è\n",
            "   üìù –û–ø–∏—Å–∞–Ω–∏–µ: –†–∞–∑–¥–µ–ª —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¢–° –∏ –¥–æ—Ä–æ–≥ (–≤ –Ω–∞—Å–µ–ª–µ–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞—Ö, –≤–Ω–µ –∏—Ö, –Ω–∞ –∞–≤—Ç–æ–º–∞–≥–∏—Å—Ç—Ä–∞–ª—è—Ö), –∞ —Ç–∞–∫–∂–µ –æ–±—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –≤—ã–±–æ—Ä–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ –≤–æ–¥–∏—Ç–µ–ª–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Å–ª–æ–≤–∏–π.\n",
            "   üéØ –°—Ö–æ–¥—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–∞: 0.705\n",
            "\n",
            "    9.1\n",
            "       –í–æ–¥–∏—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –≤–µ—Å—Ç–∏ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ —Å–æ —Å–∫–æ—Ä–æ—Å—Ç—å—é, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–µ–π —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è, —É—á–∏—Ç—ã–≤–∞—è –ø—Ä–∏ —ç—Ç–æ–º –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å –¥–≤–∏–∂–µ–Ω–∏—è, –æ—Å–æ–±–µ–Ω–Ω...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.705, –ø—É–Ω–∫—Ç=0.728\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.736\n",
            "\n",
            "    9.5\n",
            "       –í–æ–¥–∏—Ç–µ–ª—é –∑–∞–ø—Ä–µ—â–∞–µ—Ç—Å—è: –ø—Ä–µ–≤—ã—à–∞—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —Å–∫–æ—Ä–æ—Å—Ç—å, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–æ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞; –ø—Ä–µ–≤—ã—à–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å, —É–∫–∞–∑–∞–Ω–Ω—É—é ...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.705, –ø—É–Ω–∫—Ç=0.694\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.722\n",
            "\n",
            "    9.2\n",
            "       –í –Ω–∞—Å–µ–ª–µ–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–∞—Ö —Ä–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è –¥–≤–∏–∂–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ —Å–æ —Å–∫–æ—Ä–æ—Å—Ç—å—é –Ω–µ –±–æ–ª–µ–µ 60 –∫–º/—á, –∞ –≤ –∂–∏–ª—ã—Ö –∑–æ–Ω–∞—Ö –∏ –Ω–∞ –¥–≤–æ—Ä–æ–≤—ã—Ö —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏—è—Ö –Ω–µ –±–æ–ª–µ–µ 20 –∫–º...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.705, –ø—É–Ω–∫—Ç=0.690\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.720\n",
            "\n",
            "    9.4\n",
            "       –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º —Å—Ä–µ–¥—Å—Ç–≤–∞–º, –±—É–∫—Å–∏—Ä—É—é—â–∏–º –º–µ—Ö–∞–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–µ —Å—Ä–µ–¥—Å—Ç–≤–∞, —Ä–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è –¥–≤–∏–∂–µ–Ω–∏–µ —Å–æ —Å–∫–æ—Ä–æ—Å—Ç—å—é –Ω–µ –±–æ–ª–µ–µ 50 –∫–º/—á. –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º —Å—Ä–µ–¥—Å—Ç–≤–∞–º, –ø–µ...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.705, –ø—É–Ω–∫—Ç=0.672\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.713\n",
            "\n",
            "    9.3\n",
            "       –í–Ω–µ –Ω–∞—Å–µ–ª–µ–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ —Ä–∞–∑—Ä–µ—à–∞–µ—Ç—Å—è –¥–≤–∏–∂–µ–Ω–∏–µ: –ª–µ–≥–∫–æ–≤—ã–º –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º –∏ –≥—Ä—É–∑–æ–≤—ã–º –∞–≤—Ç–æ–º–æ–±–∏–ª—è–º —Å —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω–æ–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –º–∞—Å—Å–æ–π –Ω–µ –±–æ–ª–µ–µ 3,5 —Ç –Ω–∞ –∞–≤—Ç–æ–º–∞–≥–∏—Å...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.705, –ø—É–Ω–∫—Ç=0.595\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.680\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìÅ –†–ê–ó–î–ï–õ 2: 10. –û–±–≥–æ–Ω, –æ–ø–µ—Ä–µ–∂–µ–Ω–∏–µ, –≤—Å—Ç—Ä–µ—á–Ω—ã–π —Ä–∞–∑—ä–µ–∑–¥\n",
            "   üìù –û–ø–∏—Å–∞–Ω–∏–µ: –†–∞–∑–¥–µ–ª —Ä–µ–≥—É–ª–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –æ–±–≥–æ–Ω–∞ –∏ –æ–ø–µ—Ä–µ–∂–µ–Ω–∏—è: —É—Å–ª–æ–≤–∏—è, –∫–æ–≥–¥–∞ –æ–±–≥–æ–Ω —Ä–∞–∑—Ä–µ—à–µ–Ω –∏ –∑–∞–ø—Ä–µ—â–µ–Ω, –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç–∏ –≤–æ–¥–∏—Ç–µ–ª–µ–π –ø—Ä–∏ –æ–±–≥–æ–Ω–µ, –ø—Ä–∞–≤–∏–ª–∞ –≤—Å—Ç—Ä–µ—á–Ω–æ–≥–æ —Ä–∞–∑—ä–µ–∑–¥–∞.\n",
            "   üéØ –°—Ö–æ–¥—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–∞: 0.492\n",
            "\n",
            "    10.6\n",
            "       –í —Å–ª—É—á–∞–µ –µ—Å–ª–∏ –≤–Ω–µ –Ω–∞—Å–µ–ª–µ–Ω–Ω—ã—Ö –ø—É–Ω–∫—Ç–æ–≤ –æ–±–≥–æ–Ω –∏–ª–∏ –æ–ø–µ—Ä–µ–∂–µ–Ω–∏–µ —Ç–∏—Ö–æ—Ö–æ–¥–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞, –ø–µ—Ä–µ–≤–æ–∑—è—â–µ–≥–æ –∫—Ä—É–ø–Ω–æ–≥–∞–±–∞—Ä–∏—Ç–Ω—ã–π –≥—Ä...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.492, –ø—É–Ω–∫—Ç=0.584\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.591\n",
            "\n",
            "    10.3\n",
            "       –í–æ–¥–∏—Ç–µ–ª—é –æ–±–≥–æ–Ω—è–µ–º–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–≥–æ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∑–∞–ø—Ä–µ—â–∞–µ—Ç—Å—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –æ–±–≥–æ–Ω—É –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º –ø–æ–≤—ã—à–µ–Ω–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ –¥–≤–∏–∂–µ–Ω–∏—è –∏–ª–∏ –∏–Ω—ã–º–∏ –¥–µ–π—Å—Ç–≤–∏—è–º–∏.\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.492, –ø—É–Ω–∫—Ç=0.567\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.584\n",
            "\n",
            "    10.1\n",
            "       –ü—Ä–µ–∂–¥–µ —á–µ–º –Ω–∞—á–∞—Ç—å –æ–±–≥–æ–Ω, –≤–æ–¥–∏—Ç–µ–ª—å –æ–±—è–∑–∞–Ω —É–±–µ–¥–∏—Ç—å—Å—è –≤ —Ç–æ–º, —á—Ç–æ –ø–æ–ª–æ—Å–∞ –¥–≤–∏–∂–µ–Ω–∏—è, –Ω–∞ –∫–æ—Ç–æ—Ä—É—é –æ–Ω —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è –≤—ã–µ—Ö–∞—Ç—å, —Å–≤–æ–±–æ–¥–Ω–∞ –Ω–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –¥–ª—è –æ–±–≥–æ–Ω–∞ —Ä–∞...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.492, –ø—É–Ω–∫—Ç=0.555\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.580\n",
            "\n",
            "    10.7\n",
            "       –í —Å–ª—É—á–∞–µ –µ—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–Ω—ã–π —Ä–∞–∑—ä–µ–∑–¥ –∑–∞—Ç—Ä—É–¥–Ω–µ–Ω, –≤–æ–¥–∏—Ç–µ–ª—å, –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –∏–º–µ–µ—Ç—Å—è –ø—Ä–µ–ø—è—Ç—Å—Ç–≤–∏–µ, –¥–æ–ª–∂–µ–Ω —É—Å—Ç—É–ø–∏—Ç—å –¥–æ—Ä–æ–≥—É. –£—Å—Ç—É–ø–∏—Ç—å –¥–æ—Ä–æ–≥—É –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø—Ä–µ–ø...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.492, –ø—É–Ω–∫—Ç=0.505\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.561\n",
            "\n",
            "    10.5\n",
            "       –û–ø–µ—Ä–µ–∂–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ –ø—Ä–∏ –ø—Ä–æ–µ–∑–¥–µ –ø–µ—à–µ—Ö–æ–¥–Ω—ã—Ö –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è —Å —É—á–µ—Ç–æ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø—É–Ω–∫—Ç–∞ 14.2 –ü—Ä–∞–≤–∏–ª.\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.492, –ø—É–Ω–∫—Ç=0.482\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.553\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "üìÅ –†–ê–ó–î–ï–õ 3: 7. –ù–∞—á–∞–ª–æ –¥–≤–∏–∂–µ–Ω–∏—è, –º–∞–Ω–µ–≤—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
            "   üìù –û–ø–∏—Å–∞–Ω–∏–µ: –†–∞–∑–¥–µ–ª —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –º–∞–Ω–µ–≤—Ä–æ–≤: –Ω–∞—á–∞–ª–æ –¥–≤–∏–∂–µ–Ω–∏—è, –ø–µ—Ä–µ—Å—Ç—Ä–æ–µ–Ω–∏–µ, –ø–æ–≤–æ—Ä–æ—Ç—ã, —Ä–∞–∑–≤–æ—Ä–æ—Ç—ã, –¥–≤–∏–∂–µ–Ω–∏–µ –∑–∞–¥–Ω–∏–º —Ö–æ–¥–æ–º. –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å –ø–æ–¥–∞—á–∏ —Å–∏–≥–Ω–∞–ª–æ–≤, –æ—á–µ—Ä—ë–¥–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∑–¥–∞ –∏ –º–µ—Å—Ç–∞, –≥–¥–µ –º–∞–Ω–µ–≤—Ä—ã –∑–∞–ø—Ä–µ—â–µ–Ω—ã.\n",
            "   üéØ –°—Ö–æ–¥—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–∞: 0.491\n",
            "\n",
            "    7.10\n",
            "       –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –ø–æ–ª–æ—Å—ã —Ç–æ—Ä–º–æ–∂–µ–Ω–∏—è –≤–æ–¥–∏—Ç–µ–ª—å, –Ω–∞–º–µ—Ä–µ–≤–∞—é—â–∏–π—Å—è –ø–æ–≤–µ—Ä–Ω—É—Ç—å, –¥–æ–ª–∂–µ–Ω —Å–≤–æ–µ–≤—Ä–µ–º–µ–Ω–Ω–æ –ø–µ—Ä–µ—Å—Ç—Ä–æ–∏—Ç—å—Å—è –Ω–∞ —ç—Ç—É –ø–æ–ª–æ—Å—É –∏ —Å–Ω–∏–∂–∞—Ç—å —Å–∫–æ—Ä–æ—Å—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ –Ω–µ–π. –ü—Ä...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.491, –ø—É–Ω–∫—Ç=0.565\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.583\n",
            "\n",
            "    7.9\n",
            "       –í —Å–ª—É—á–∞—è—Ö, –∫–æ–≥–¥–∞ —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –¥–≤–∏–∂–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å—Ä–µ–¥—Å—Ç–≤ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è, –∞ –æ—á–µ—Ä–µ–¥–Ω–æ—Å—Ç—å –ø—Ä–æ–µ–∑–¥–∞ –Ω–µ –æ–≥–æ–≤–æ—Ä–µ–Ω–∞ –ü—Ä–∞–≤–∏–ª–∞–º–∏, –¥–æ—Ä–æ–≥—É –¥–æ–ª–∂–µ–Ω —É—Å—Ç—É–ø–∏—Ç—å –≤–æ–¥–∏—Ç–µ–ª—å,...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.491, –ø—É–Ω–∫—Ç=0.511\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.563\n",
            "\n",
            "    7.6\n",
            "       –ü–æ–≤–æ—Ä–æ—Ç –¥–æ–ª–∂–µ–Ω –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å—Å—è —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –ø—Ä–∏ –≤—ã–µ–∑–¥–µ —Å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –ø—Ä–æ–µ–∑–∂–∏—Ö —á–∞—Å—Ç–µ–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ –Ω–µ –æ–∫–∞–∑–∞–ª–æ—Å—å –Ω–∞ —Å—Ç–æ—Ä–æ–Ω–µ –≤—Å—Ç—Ä–µ—á–Ω–æ–≥–æ –¥...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.491, –ø—É–Ω–∫—Ç=0.508\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.562\n",
            "\n",
            "    7.3\n",
            "       –ü—Ä–∏ –≤—ã–µ–∑–¥–µ –Ω–∞ –¥–æ—Ä–æ–≥—É —Å –ø—Ä–∏–ª–µ–≥–∞—é—â–µ–π —Ç–µ—Ä—Ä–∏—Ç–æ—Ä–∏–∏ –≤–æ–¥–∏—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω —É—Å—Ç—É–ø–∏—Ç—å –¥–æ—Ä–æ–≥—É —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã–º —Å—Ä–µ–¥—Å—Ç–≤–∞–º –∏ –ø–µ—à–µ—Ö–æ–¥–∞–º, –¥–≤–∏–∂—É—â–∏–º—Å—è –ø–æ –Ω–µ–π, –∞ –ø—Ä–∏ —Å—ä–µ–∑–¥–µ —Å –¥–æ...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.491, –ø—É–Ω–∫—Ç=0.495\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.558\n",
            "\n",
            "    7.5\n",
            "       –ü–µ—Ä–µ–¥ –ø–æ–≤–æ—Ä–æ—Ç–æ–º –Ω–∞–ø—Ä–∞–≤–æ, –Ω–∞–ª–µ–≤–æ –∏–ª–∏ —Ä–∞–∑–≤–æ—Ä–æ—Ç–æ–º –≤–æ–¥–∏—Ç–µ–ª—å –æ–±—è–∑–∞–Ω –∑–∞–±–ª–∞–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–Ω—è—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∫—Ä–∞–π–Ω–µ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–µ–∑–∂–µ–π —á–∞—Å—Ç–∏, –ø—Ä–µ–¥–Ω–∞–∑–Ω–∞—á–µ...\n",
            "       üéØ –°—Ö–æ–¥—Å—Ç–≤–æ: —Ä–∞–∑–¥–µ–ª=0.491, –ø—É–Ω–∫—Ç=0.495\n",
            "       üìà –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π score: 0.557\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!\n"
          ]
        }
      ]
    }
  ]
}